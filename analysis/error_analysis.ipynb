{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05ae70df",
   "metadata": {},
   "source": [
    "### No action, no response. Empty reasoning steps & empty answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49c451e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"gpt4o\":\"gpt4o_results_final.json\", \"videollama\": \"videollama3_results_final 2.json\", \"internv\":\"internvl3_results_final.json\", \"gemini\":\"gemini_results_final.json\", \"qwen\": \"qwen2_5_results_final.json\", \"pixtral\": \"pixtral_results_final.json\", \"mplugowl\":\"mplugowl_results_final.json\", \"o4\":\"o4_mini_results_final 1.json\", \"gemini25\":\"gemini25_results_final 1.json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d7f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def check_empty_reasoning_and_final_answer(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    total_samples = len(data)\n",
    "    empty_both_count = 0\n",
    "    empty_both_indices = []\n",
    "\n",
    "    for entry in data:\n",
    "        for key, value in entry.items():\n",
    "            reasoning_empty = not value.get(\"reasoning_steps\")\n",
    "\n",
    "            final_answer = value.get(\"final_answer\", {})\n",
    "            if isinstance(final_answer, dict):\n",
    "                final_answer_empty = not final_answer.get(\"value\")\n",
    "            else:\n",
    "                final_answer_empty = True  # If it's not a dict, we assume it's invalid/empty\n",
    "\n",
    "            if reasoning_empty and final_answer_empty:\n",
    "                empty_both_count += 1\n",
    "                empty_both_indices.append(int(key))\n",
    "\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Samples with empty 'reasoning_steps' AND empty 'final_answer': {empty_both_count}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ea67c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: pixtral_results_final.json\n",
      "Total samples: 828\n",
      "Samples with empty 'reasoning_steps' AND empty 'final_answer': 84\n",
      "\n",
      "File: mplugowl_results_final.json\n",
      "Total samples: 828\n",
      "Samples with empty 'reasoning_steps' AND empty 'final_answer': 92\n",
      "\n",
      "File: o4_mini_results_final 1.json\n",
      "Total samples: 825\n",
      "Samples with empty 'reasoning_steps' AND empty 'final_answer': 19\n",
      "\n",
      "File: gemini25_results_final 1.json\n",
      "Total samples: 828\n",
      "Samples with empty 'reasoning_steps' AND empty 'final_answer': 52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_empty_reasoning_and_final_answer(models['pixtral'])\n",
    "check_empty_reasoning_and_final_answer(models['mplugowl'])\n",
    "check_empty_reasoning_and_final_answer(models['o4'])\n",
    "check_empty_reasoning_and_final_answer(models['gemini25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e493377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: qwen2_5_results_final.json\n",
      "Total samples: 828\n",
      "Samples with empty 'reasoning_steps' AND empty 'final_answer': 25\n",
      "\n",
      "File: videollama3_results_final 2.json\n",
      "Total samples: 828\n",
      "Samples with empty 'reasoning_steps' AND empty 'final_answer': 76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_empty_reasoning_and_final_answer(models['qwen'])\n",
    "check_empty_reasoning_and_final_answer(models['videollama'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efadb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: gpt4o_results_final.json\n",
      "Total samples: 827\n",
      "Samples with empty 'reasoning_steps' AND empty 'final_answer': 156\n",
      "\n",
      "File: internvl3_results_final.json\n",
      "Total samples: 828\n",
      "Samples with empty 'reasoning_steps' AND empty 'final_answer': 172\n",
      "\n",
      "File: videollama3_results_final 2.json\n",
      "Total samples: 828\n",
      "Samples with empty 'reasoning_steps' AND empty 'final_answer': 76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_empty_reasoning_and_final_answer(models['gpt4o'])\n",
    "check_empty_reasoning_and_final_answer(models['internv'])\n",
    "check_empty_reasoning_and_final_answer(models['videollama'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee238c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: gemini_results_final.json\n",
      "Total samples: 828\n",
      "Samples with empty 'reasoning_steps' AND empty 'final_answer': 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_empty_reasoning_and_final_answer(models['gemini'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e61380",
   "metadata": {},
   "source": [
    "### No action, the whole response is model thought - Empty reasoning steps but not empty final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8630e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def check_reasoning_empty_but_final_exists(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    total_samples = len(data)\n",
    "    count = 0\n",
    "    indices = []\n",
    "\n",
    "    for entry in data:\n",
    "        for key, value in entry.items():\n",
    "            reasoning_empty = not value.get(\"reasoning_steps\")\n",
    "\n",
    "            final_answer = value.get(\"final_answer\", {})\n",
    "            if isinstance(final_answer, dict):\n",
    "                final_answer_exists = bool(final_answer.get(\"value\"))\n",
    "            else:\n",
    "                final_answer_exists = False  # Ignore if final_answer is not a valid dict\n",
    "\n",
    "            if reasoning_empty and final_answer_exists:\n",
    "                count += 1\n",
    "                indices.append(int(key))\n",
    "\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Samples with empty 'reasoning_steps' BUT non-empty 'final_answer': {count}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0385181e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: pixtral_results_final.json\n",
      "Total samples: 828\n",
      "Samples with empty 'reasoning_steps' BUT non-empty 'final_answer': 0\n",
      "\n",
      "File: mplugowl_results_final.json\n",
      "Total samples: 828\n",
      "Samples with empty 'reasoning_steps' BUT non-empty 'final_answer': 0\n",
      "\n",
      "File: o4_mini_results_final 1.json\n",
      "Total samples: 825\n",
      "Samples with empty 'reasoning_steps' BUT non-empty 'final_answer': 0\n",
      "\n",
      "File: gemini25_results_final 1.json\n",
      "Total samples: 828\n",
      "Samples with empty 'reasoning_steps' BUT non-empty 'final_answer': 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_reasoning_empty_but_final_exists(models['pixtral'])\n",
    "check_reasoning_empty_but_final_exists(models['mplugowl'])\n",
    "check_reasoning_empty_but_final_exists(models['o4'])\n",
    "check_reasoning_empty_but_final_exists(models['gemini25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c4d629a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: qwen2_5_results_final.json\n",
      "Total samples: 828\n",
      "Samples with empty 'reasoning_steps' BUT non-empty 'final_answer': 0\n",
      "\n",
      "File: videollama3_results_final 2.json\n",
      "Total samples: 828\n",
      "Samples with empty 'reasoning_steps' BUT non-empty 'final_answer': 28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_reasoning_empty_but_final_exists(models['qwen'])\n",
    "check_reasoning_empty_but_final_exists(models['videollama'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea972be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: gpt4o_results_final.json\n",
      "Total samples: 827\n",
      "Samples with empty 'reasoning_steps' BUT non-empty 'final_answer': 0\n",
      "\n",
      "File: internvl3_results_final.json\n",
      "Total samples: 828\n",
      "Samples with empty 'reasoning_steps' BUT non-empty 'final_answer': 0\n",
      "\n",
      "File: videollama3_results_final 2.json\n",
      "Total samples: 828\n",
      "Samples with empty 'reasoning_steps' BUT non-empty 'final_answer': 28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_reasoning_empty_but_final_exists(models['gpt4o'])\n",
    "check_reasoning_empty_but_final_exists(models['internv'])\n",
    "check_reasoning_empty_but_final_exists(models['videollama'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21416b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: gemini_results_final.json\n",
      "Total samples: 828\n",
      "Samples with empty 'reasoning_steps' BUT non-empty 'final_answer': 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_reasoning_empty_but_final_exists(models['gemini'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bbc2ae",
   "metadata": {},
   "source": [
    "### Invalid JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a97c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def check_invalid_format(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    total_samples = len(data)\n",
    "    invalid_samples = 0\n",
    "    invalid_indices = []\n",
    "\n",
    "    required_top_keys = {\"query\", \"filename\", \"final_answer\"}\n",
    "    required_step_keys = {\"step\", \"task\", \"tool_used\", \"tool_output\", \"thought\"}\n",
    "\n",
    "    for entry in data:\n",
    "        for key, value in entry.items():\n",
    "            index = int(key)\n",
    "            # Check top-level keys\n",
    "            if not all(k in value for k in required_top_keys):\n",
    "                invalid_samples += 1\n",
    "                invalid_indices.append(index)\n",
    "                continue  # Skip further checks for this sample\n",
    "\n",
    "            # Check final_answer structure\n",
    "            final_answer = value.get(\"final_answer\")\n",
    "            if not isinstance(final_answer, dict) or \"value\" not in final_answer or \"justification\" not in final_answer:\n",
    "                invalid_samples += 1\n",
    "                invalid_indices.append(index)\n",
    "                continue\n",
    "\n",
    "            # Check reasoning_steps format (if present)\n",
    "            reasoning_steps = value.get(\"reasoning_steps\", [])\n",
    "            if not isinstance(reasoning_steps, list):\n",
    "                invalid_samples += 1\n",
    "                invalid_indices.append(index)\n",
    "                continue\n",
    "\n",
    "            for step in reasoning_steps:\n",
    "                if not isinstance(step, dict) or not required_step_keys.issubset(step):\n",
    "                    invalid_samples += 1\n",
    "                    invalid_indices.append(index)\n",
    "                    break  # No need to check more steps in this sample\n",
    "\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Samples with Invalid JSON format in argument specification: {invalid_samples}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5a66460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: pixtral_results_final.json\n",
      "Total samples: 828\n",
      "Samples with Invalid JSON format in argument specification: 512\n",
      "\n",
      "File: mplugowl_results_final.json\n",
      "Total samples: 828\n",
      "Samples with Invalid JSON format in argument specification: 828\n",
      "\n",
      "File: o4_mini_results_final 1.json\n",
      "Total samples: 825\n",
      "Samples with Invalid JSON format in argument specification: 177\n",
      "\n",
      "File: gemini25_results_final 1.json\n",
      "Total samples: 828\n",
      "Samples with Invalid JSON format in argument specification: 326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_invalid_format(models['pixtral'])\n",
    "check_invalid_format(models['mplugowl'])\n",
    "check_invalid_format(models['o4'])\n",
    "check_invalid_format(models['gemini25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c553230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: qwen2_5_results_final.json\n",
      "Total samples: 828\n",
      "Samples with Invalid JSON format in argument specification: 317\n",
      "\n",
      "File: videollama3_results_final 2.json\n",
      "Total samples: 828\n",
      "Samples with Invalid JSON format in argument specification: 190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_invalid_format(models['qwen'])\n",
    "check_invalid_format(models['videollama'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4dff8444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: gpt4o_results_final.json\n",
      "Total samples: 827\n",
      "Samples with Invalid JSON format in argument specification: 235\n",
      "\n",
      "File: internvl3_results_final.json\n",
      "Total samples: 828\n",
      "Samples with Invalid JSON format in argument specification: 454\n",
      "\n",
      "File: videollama3_results_final 2.json\n",
      "Total samples: 828\n",
      "Samples with Invalid JSON format in argument specification: 190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_invalid_format(models['gpt4o'])\n",
    "check_invalid_format(models['internv'])\n",
    "check_invalid_format(models['videollama'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "613084dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: gemini_results_final.json\n",
      "Total samples: 828\n",
      "Samples with Invalid JSON format in argument specification: 755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_invalid_format(models['gemini'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b40928",
   "metadata": {},
   "source": [
    "### Multiple tool calls in a single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a108c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def check_tool_conflicts_and_repeats(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    total_samples = len(data)\n",
    "    conflict_count = 0\n",
    "    repetition_count = 0\n",
    "\n",
    "    conflict_indices = []\n",
    "    repetition_indices = []\n",
    "\n",
    "    for entry in data:\n",
    "        for key, value in entry.items():\n",
    "            index = int(key)\n",
    "            reasoning_steps = value.get(\"reasoning_steps\", [])\n",
    "            prev_tool = None\n",
    "            has_conflict = False\n",
    "            has_repetition = False\n",
    "\n",
    "            for step in reasoning_steps:\n",
    "                if not isinstance(step, dict):\n",
    "                    continue\n",
    "\n",
    "                # Extract both tool fields\n",
    "                tool_used = step.get(\"tool_used\")\n",
    "                tool = step.get(\"tool\")\n",
    "\n",
    "                # Normalize both if they exist\n",
    "                tool_used_str = tool_used.strip().lower() if isinstance(tool_used, str) else None\n",
    "                tool_str = tool.strip().lower() if isinstance(tool, str) else None\n",
    "\n",
    "                # ----- Check for TOOL CONFLICT (both fields present with different values)\n",
    "                if tool_str and tool_used_str and tool_str != tool_used_str:\n",
    "                    has_conflict = True\n",
    "\n",
    "                # Pick the effective tool for this step\n",
    "                current_tool = tool_used_str or tool_str\n",
    "\n",
    "                # ----- Check for REPETITION of the same tool in consecutive steps\n",
    "                if current_tool and prev_tool == current_tool:\n",
    "                    has_repetition = True\n",
    "\n",
    "                prev_tool = current_tool\n",
    "\n",
    "            if has_conflict:\n",
    "                conflict_count += 1\n",
    "                conflict_indices.append(index)\n",
    "            if has_repetition:\n",
    "                repetition_count += 1\n",
    "                repetition_indices.append(index)\n",
    "\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Samples with conflicting tool fields: {conflict_count}\")\n",
    "    print(f\"Conflict Indices: {conflict_indices}\")\n",
    "    print(f\"Samples with repeated tool in consecutive steps: {repetition_count}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a0e9796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: pixtral_results_final.json\n",
      "Total samples: 828\n",
      "Samples with conflicting tool fields: 0\n",
      "Conflict Indices: []\n",
      "Samples with repeated tool in consecutive steps: 45\n",
      "\n",
      "File: mplugowl_results_final.json\n",
      "Total samples: 828\n",
      "Samples with conflicting tool fields: 0\n",
      "Conflict Indices: []\n",
      "Samples with repeated tool in consecutive steps: 153\n",
      "\n",
      "File: o4_mini_results_final 1.json\n",
      "Total samples: 825\n",
      "Samples with conflicting tool fields: 0\n",
      "Conflict Indices: []\n",
      "Samples with repeated tool in consecutive steps: 162\n",
      "\n",
      "File: gemini25_results_final 1.json\n",
      "Total samples: 828\n",
      "Samples with conflicting tool fields: 0\n",
      "Conflict Indices: []\n",
      "Samples with repeated tool in consecutive steps: 213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_tool_conflicts_and_repeats(models['pixtral'])\n",
    "check_tool_conflicts_and_repeats(models['mplugowl'])\n",
    "check_tool_conflicts_and_repeats(models['o4'])\n",
    "check_tool_conflicts_and_repeats(models['gemini25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6479b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: gpt4o_results_final.json\n",
      "Total samples: 827\n",
      "Samples with conflicting tool fields: 1\n",
      "Conflict Indices: [644]\n",
      "Samples with repeated tool in consecutive steps: 117\n",
      "\n",
      "File: internvl3_results_final.json\n",
      "Total samples: 828\n",
      "Samples with conflicting tool fields: 0\n",
      "Conflict Indices: []\n",
      "Samples with repeated tool in consecutive steps: 126\n",
      "\n",
      "File: videollama3_results_final 2.json\n",
      "Total samples: 828\n",
      "Samples with conflicting tool fields: 0\n",
      "Conflict Indices: []\n",
      "Samples with repeated tool in consecutive steps: 117\n",
      "\n",
      "File: qwen2_5_results_final.json\n",
      "Total samples: 828\n",
      "Samples with conflicting tool fields: 0\n",
      "Conflict Indices: []\n",
      "Samples with repeated tool in consecutive steps: 149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_tool_conflicts_and_repeats(models['gpt4o'])\n",
    "check_tool_conflicts_and_repeats(models['internv'])\n",
    "check_tool_conflicts_and_repeats(models['videollama'])\n",
    "check_tool_conflicts_and_repeats(models['qwen'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "581d5cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: gemini_results_final.json\n",
      "Total samples: 828\n",
      "Samples with conflicting tool fields: 0\n",
      "Conflict Indices: []\n",
      "Samples with repeated tool in consecutive steps: 172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_tool_conflicts_and_repeats(models['gemini'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbd32ed",
   "metadata": {},
   "source": [
    "### Final answer generation without adhering to the format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee67ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def check_invalid_format_but_has_final_answer(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    total_samples = len(data)\n",
    "    count = 0\n",
    "    indices = []\n",
    "\n",
    "    required_top_keys = {\"query\", \"filename\", \"final_answer\"}\n",
    "    required_step_keys = {\"step\", \"task\", \"tool_used\", \"tool_output\", \"thought\"}\n",
    "\n",
    "    for entry in data:\n",
    "        for key, value in entry.items():\n",
    "            index = int(key)\n",
    "\n",
    "            # Check if final_answer is present and has value\n",
    "            final_answer = value.get(\"final_answer\")\n",
    "            final_answer_ok = isinstance(final_answer, dict) and bool(final_answer.get(\"value\"))\n",
    "\n",
    "            if not final_answer_ok:\n",
    "                continue  # Skip — only interested in cases where final_answer exists\n",
    "\n",
    "            # Check top-level format\n",
    "            if not all(k in value for k in required_top_keys):\n",
    "                count += 1\n",
    "                indices.append(index)\n",
    "                continue\n",
    "\n",
    "            # Check final_answer structure\n",
    "            if \"justification\" not in final_answer:\n",
    "                count += 1\n",
    "                indices.append(index)\n",
    "                continue\n",
    "\n",
    "            # Check reasoning_steps format\n",
    "            reasoning_steps = value.get(\"reasoning_steps\", [])\n",
    "            if not isinstance(reasoning_steps, list):\n",
    "                count += 1\n",
    "                indices.append(index)\n",
    "                continue\n",
    "\n",
    "            for step in reasoning_steps:\n",
    "                if not isinstance(step, dict) or not required_step_keys.issubset(step):\n",
    "                    count += 1\n",
    "                    indices.append(index)\n",
    "                    break\n",
    "\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Samples with INVALID format but VALID final_answer: {count}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d46155d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: pixtral_results_final.json\n",
      "Total samples: 828\n",
      "Samples with INVALID format but VALID final_answer: 428\n",
      "\n",
      "File: mplugowl_results_final.json\n",
      "Total samples: 828\n",
      "Samples with INVALID format but VALID final_answer: 736\n",
      "\n",
      "File: o4_mini_results_final 1.json\n",
      "Total samples: 825\n",
      "Samples with INVALID format but VALID final_answer: 143\n",
      "\n",
      "File: gemini25_results_final 1.json\n",
      "Total samples: 828\n",
      "Samples with INVALID format but VALID final_answer: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_invalid_format_but_has_final_answer(models['pixtral'])\n",
    "check_invalid_format_but_has_final_answer(models['mplugowl'])\n",
    "check_invalid_format_but_has_final_answer(models['o4'])\n",
    "check_invalid_format_but_has_final_answer(models['gemini25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4a7a82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: gemini_results_final.json\n",
      "Total samples: 828\n",
      "Samples with INVALID format but VALID final_answer: 174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_invalid_format_but_has_final_answer(models['gemini'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89cab3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: qwen2_5_results_final.json\n",
      "Total samples: 828\n",
      "Samples with INVALID format but VALID final_answer: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_invalid_format_but_has_final_answer(models['qwen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e740383a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: gpt4o_results_final.json\n",
      "Total samples: 827\n",
      "Samples with INVALID format but VALID final_answer: 60\n",
      "\n",
      "File: internvl3_results_final.json\n",
      "Total samples: 828\n",
      "Samples with INVALID format but VALID final_answer: 220\n",
      "\n",
      "File: videollama3_results_final 2.json\n",
      "Total samples: 828\n",
      "Samples with INVALID format but VALID final_answer: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_invalid_format_but_has_final_answer(models['gpt4o'])\n",
    "check_invalid_format_but_has_final_answer(models['internv'])\n",
    "check_invalid_format_but_has_final_answer(models['videollama'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913decb6",
   "metadata": {},
   "source": [
    "### Misinterpreting visual content (e.g., wrong object recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d79de1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy==3.5.4\n",
      "  Downloading spacy-3.5.4-cp311-cp311-win_amd64.whl.metadata (25 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy==3.5.4)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy==3.5.4)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy==3.5.4)\n",
      "  Downloading murmurhash-1.0.13-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy==3.5.4)\n",
      "  Downloading cymem-2.0.11-cp311-cp311-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy==3.5.4)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.8 (from spacy==3.5.4)\n",
      "  Downloading thinc-8.1.12-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy==3.5.4)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy==3.5.4)\n",
      "  Downloading srsly-2.5.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy==3.5.4)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy==3.5.4)\n",
      "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pathy>=0.10.0 (from spacy==3.5.4)\n",
      "  Downloading pathy-0.11.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1 (from spacy==3.5.4)\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy==3.5.4) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy==3.5.4) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy==3.5.4) (2.32.3)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 (from spacy==3.5.4)\n",
      "  Downloading pydantic-1.10.22-cp311-cp311-win_amd64.whl.metadata (155 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy==3.5.4) (3.1.4)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: setuptools in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy==3.5.4) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy==3.5.4) (23.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy==3.5.4)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy==3.5.4)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pathlib-abc==0.1.1 (from pathy>=0.10.0->spacy==3.5.4)\n",
      "  Downloading pathlib_abc-0.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy==3.5.4) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.4) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.4) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.4) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.4) (2022.12.7)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.2.0,>=8.1.8->spacy==3.5.4)\n",
      "  Downloading blis-0.7.11-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.2.0,>=8.1.8->spacy==3.5.4)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy==3.5.4) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy==3.5.4) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy==3.5.4) (2.1.2)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.5.4)\n",
      "  Downloading marisa_trie-1.2.1-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Downloading spacy-3.5.4-cp311-cp311-win_amd64.whl (12.2 MB)\n",
      "   ---------------------------------------- 12.2/12.2 MB 4.4 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.13-cp311-cp311-win_amd64.whl (24 kB)\n",
      "Downloading pathy-0.11.0-py3-none-any.whl (47 kB)\n",
      "Downloading pathlib_abc-0.1.1-py3-none-any.whl (23 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "Downloading pydantic-1.10.22-cp311-cp311-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 2.3/2.3 MB 32.5 MB/s eta 0:00:00\n",
      "Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp311-cp311-win_amd64.whl (632 kB)\n",
      "   --------------------------------------- 632.6/632.6 kB 11.6 MB/s eta 0:00:00\n",
      "Downloading thinc-8.1.12-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 1.5/1.5 MB 39.2 MB/s eta 0:00:00\n",
      "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading blis-0.7.11-cp311-cp311-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 6.6/6.6 MB 6.9 MB/s eta 0:00:00\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 5.4/5.4 MB 21.8 MB/s eta 0:00:00\n",
      "Downloading marisa_trie-1.2.1-cp311-cp311-win_amd64.whl (152 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, pydantic, pathlib-abc, murmurhash, marisa-trie, catalogue, blis, typer, srsly, preshed, language-data, pathy, langcodes, confection, thinc, spacy\n",
      "Successfully installed blis-0.7.11 catalogue-2.0.10 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.13 pathlib-abc-0.1.1 pathy-0.11.0 preshed-3.0.9 pydantic-1.10.22 smart-open-6.4.0 spacy-3.5.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.1.12 typer-0.9.4 wasabi-1.1.3\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     --------------------------------------- 12.8/12.8 MB 22.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from en-core-web-sm==3.5.0) (3.5.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.9.4)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.22)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.3.0)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from pathy>=0.10.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\amals\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\amals\\appdata\\roaming\\python\\python311\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.2.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.5.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 14:20:24.288071: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-23 14:20:35.280741: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy==3.5.4 --user\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc129df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_top_21_keywords(text):\n",
    "    doc = nlp(text)\n",
    "    noun_chunks = [chunk.text.lower().strip() for chunk in doc.noun_chunks if 1 < len(chunk.text.strip()) < 30]\n",
    "    tokens = [token.lemma_.lower().strip() for token in doc if token.pos_ in {\"NOUN\", \"PROPN\"} and not token.is_stop and 1 < len(token) < 30]\n",
    "    keywords = noun_chunks + tokens\n",
    "    counter = Counter(keywords)\n",
    "    top_keywords = [kw for kw, _ in counter.most_common(21)]\n",
    "    return top_keywords\n",
    "\n",
    "def extract_gt_keywords(gt_path):\n",
    "    with open(gt_path, encoding=\"utf-8\") as f:\n",
    "        gt_data = json.load(f)\n",
    "\n",
    "\n",
    "    keywords_per_entry = {}\n",
    "\n",
    "    for key, entry_list in gt_data.items():\n",
    "        if not entry_list or not isinstance(entry_list, list):\n",
    "            continue\n",
    "\n",
    "        entry = entry_list[0]\n",
    "        final_answer = entry.get(\"final_answer\", {})\n",
    "        text = f\"{final_answer.get('value', '')} {final_answer.get('justification', '')}\"\n",
    "\n",
    "        if text.strip():\n",
    "            keywords = extract_top_21_keywords(text)\n",
    "            keywords_per_entry[key] = keywords\n",
    "\n",
    "    return keywords_per_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b948eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_keywords = extract_gt_keywords(\"data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c6af84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gt_keywords_in_predictions(gt_keywords, pred_path_or_data):\n",
    "    # Load pred.json if passed as a file path\n",
    "    if isinstance(pred_path_or_data, str):\n",
    "        with open(pred_path_or_data) as f:\n",
    "            pred_data = json.load(f)\n",
    "    else:\n",
    "        pred_data = pred_path_or_data  # already-loaded list\n",
    "\n",
    "    report = {}\n",
    "\n",
    "    for item in pred_data:  # item = {\"0\": {...}}, {\"1\": {...}}, ...\n",
    "        key = list(item.keys())[0]\n",
    "        pred_entry = item[key]\n",
    "\n",
    "        final_answer = pred_entry.get(\"final_answer\", {})\n",
    "        if isinstance(final_answer, str):\n",
    "            pred_text = final_answer.lower()\n",
    "        else:\n",
    "            pred_text = f\"{final_answer.get('value', '')} {final_answer.get('justification', '')}\".lower()\n",
    "\n",
    "        \n",
    "        gt_kw_list = gt_keywords.get(key, [])\n",
    "        matched = [kw for kw in gt_kw_list if kw.lower() in pred_text]\n",
    "        unmatched = [kw for kw in gt_kw_list if kw.lower() not in pred_text]\n",
    "\n",
    "        report[key] = {\n",
    "            \"gt_keywords\": gt_kw_list,\n",
    "            \"pred_text\": pred_text,\n",
    "            \"matched\": matched,\n",
    "            \"unmatched\": unmatched,\n",
    "            \"match_count\": len(matched)\n",
    "        }\n",
    "\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a449887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixtral_answer = check_gt_keywords_in_predictions(gt_keywords, models['pixtral'])\n",
    "mplugowl_answer = check_gt_keywords_in_predictions(gt_keywords, models['mplugowl'])\n",
    "o4_answer = check_gt_keywords_in_predictions(gt_keywords, models['o4'])\n",
    "gemini25_answer = check_gt_keywords_in_predictions(gt_keywords, models['gemini25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ed02126",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_answer = check_gt_keywords_in_predictions(gt_keywords, models['gemini'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cd1fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_answer = check_gt_keywords_in_predictions(gt_keywords, models['gpt4o'])\n",
    "internv_answer = check_gt_keywords_in_predictions(gt_keywords, models['internv'])\n",
    "videollama_answer = check_gt_keywords_in_predictions(gt_keywords, models['videollama'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9057d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_answer = check_gt_keywords_in_predictions(gt_keywords, models['qwen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c46f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_binary_score(report, model):\n",
    "    count = 0\n",
    "    for k, v in report.items():\n",
    "        if v[\"match_count\"] < 1:\n",
    "            count+=1 \n",
    "    print(\"For model\", model, \"the number of samples that have less than 1 matching keywords with the GT: \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cec9ed88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model pixtral the number of samples that have less than 1 matching keywords with the GT:  92\n",
      "For model mplugowl the number of samples that have less than 1 matching keywords with the GT:  98\n",
      "For model o4 the number of samples that have less than 1 matching keywords with the GT:  34\n",
      "For model gemini25 the number of samples that have less than 1 matching keywords with the GT:  60\n"
     ]
    }
   ],
   "source": [
    "compute_binary_score(pixtral_answer, 'pixtral')\n",
    "compute_binary_score(mplugowl_answer, 'mplugowl')\n",
    "compute_binary_score(o4_answer, 'o4')\n",
    "compute_binary_score(gemini25_answer, 'gemini25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d81c95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model qwen the number of samples that have less than 1 matching keywords with the GT:  33\n"
     ]
    }
   ],
   "source": [
    "\n",
    "compute_binary_score(qwen_answer, 'qwen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85d072c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model gemini the number of samples that have less than 1 matching keywords with the GT:  581\n"
     ]
    }
   ],
   "source": [
    "compute_binary_score(gemini_answer, 'gemini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0957e66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model gpt the number of samples that have less than 1 matching keywords with the GT:  165\n",
      "For model internvl the number of samples that have less than 1 matching keywords with the GT:  189\n",
      "For model videollama the number of samples that have less than 1 matching keywords with the GT:  101\n"
     ]
    }
   ],
   "source": [
    "compute_binary_score(gpt_answer, 'gpt')\n",
    "compute_binary_score(internv_answer, 'internvl')\n",
    "compute_binary_score(videollama_answer, 'videollama')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407c2343",
   "metadata": {},
   "source": [
    "### Incorrect spatial reasoning (e.g., wrong relative position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa48f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_top_21_keywords(text):\n",
    "    doc = nlp(text)\n",
    "    noun_chunks = [chunk.text.lower().strip() for chunk in doc.noun_chunks if 1 < len(chunk.text.strip()) < 30]\n",
    "    tokens = [token.lemma_.lower().strip() for token in doc if token.pos_ in {\"NOUN\", \"PROPN\"} and not token.is_stop and 1 < len(token) < 30]\n",
    "    keywords = noun_chunks + tokens\n",
    "    counter = Counter(keywords)\n",
    "    top_keywords = [kw for kw, _ in counter.most_common(21)]\n",
    "    return top_keywords\n",
    "\n",
    "\n",
    "def extract_gt_keywords_from_reasoning(gt_path):\n",
    "    import json\n",
    "    with open(gt_path, encoding=\"utf-8\") as f:\n",
    "        gt_data = json.load(f)\n",
    "\n",
    "    keywords_per_entry = {}\n",
    "\n",
    "    for key, entry_list in gt_data.items():\n",
    "        if not entry_list or not isinstance(entry_list, list):\n",
    "            continue\n",
    "\n",
    "        entry = entry_list[0]\n",
    "        steps = entry.get(\"reasoning_steps\", [])\n",
    "\n",
    "        # 🛡️ If wrapped in outer list (i.e., [[{...}]]), unwrap it\n",
    "        if len(steps) == 1 and isinstance(steps[0], list):\n",
    "            steps = steps[0]\n",
    "\n",
    "        reasoning_parts = []\n",
    "        for step in steps:\n",
    "            if not isinstance(step, dict):  # skip malformed\n",
    "                continue\n",
    "            for field in [\"task\", \"tool\", \"output\", \"thought\"]:\n",
    "                val = step.get(field, \"\")\n",
    "                if isinstance(val, (list, dict)):\n",
    "                    val = json.dumps(val)\n",
    "                reasoning_parts.append(str(val))\n",
    "\n",
    "        reasoning_text = \" \".join(reasoning_parts)\n",
    "        if reasoning_text.strip():\n",
    "            keywords = extract_top_21_keywords(reasoning_text)\n",
    "            keywords_per_entry[key] = keywords\n",
    "\n",
    "    return keywords_per_entry\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "055cb315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 0 → Keywords: ['box', 'value', \"'value\", 'line', 'orange', 'chart', 'change', 'scenedescriber', 'the chart', 'ocr', 'each line', 'bubblegum', 'brown', 'trend', 'axis', 'cornflower', 'height', 'the image', 'a line chart', 'text', 'the average height']\n",
      "Key: 1 → Keywords: ['woman', 'objectcounter', 'bananas', 'box', 'video', 'banana', 'consistency', 'count', 'number', 'the video', 'the number', 'women', 'x1', 'y1', 'x2', 'y2', 'how many women', '2 women', 'we', 'still 2 women', 'the same number']\n",
      "Key: 2 → Keywords: ['x1', 'y1', 'x2', 'y2', 'object', 'price_range', 'laptop', 'candle', 'the objects', 'the table', 'glass jars', 'candles', 'pricing', 'websearch', 'table', 'glass', 'jar', 'a laptop', 'a wooden desk', 'clothespins', 'which']\n",
      "Key: 3 → Keywords: ['people', 'text', 'scene', 'scenedescriber', 'objectcounter', 'video', 'courtroom', 'the video', 'the location', 'the image', 'storyful', 'duties', 'location', 'image', 'ocr', 'lorain', 'municipal', 'court', 'tool', 'duty', 'the scene']\n",
      "Key: 4 → Keywords: ['green', 'dark violet', 'dark', 'violet', 'segment', 'sienna', 'degree', 'estimate', 'color', 'all segments', 'medium periwinkle', 'navy blue', 'black', 'observe', '25%', 'scenedescriber', 'medium', 'periwinkle', 'navy', 'blue', 'percentage']\n"
     ]
    }
   ],
   "source": [
    "reasoning_keywords = extract_gt_keywords_from_reasoning(\"data.json\")\n",
    "\n",
    "for k, v in list(reasoning_keywords.items())[:5]:\n",
    "    print(f\"Key: {k} → Keywords: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e09a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gt_keywords_in_pred_reasoning(gt_keywords, pred_path_or_data):\n",
    "    import json\n",
    "\n",
    "    # Load predictions from file if needed\n",
    "    if isinstance(pred_path_or_data, str):\n",
    "        with open(pred_path_or_data) as f:\n",
    "            pred_data = json.load(f)\n",
    "    else:\n",
    "        pred_data = pred_path_or_data\n",
    "\n",
    "    report = {}\n",
    "\n",
    "    for item in pred_data:  # item = {\"0\": {...}}, etc.\n",
    "        key = list(item.keys())[0]\n",
    "        pred_entry = item[key]\n",
    "\n",
    "        # Extract and flatten all reasoning text fields\n",
    "        reasoning_steps = pred_entry.get(\"reasoning_steps\", [])\n",
    "        reasoning_parts = []\n",
    "\n",
    "        for step in reasoning_steps:\n",
    "            for field in [\"task\", \"tool_used\", \"tool_output\", \"thought\"]:\n",
    "                val = step.get(field, \"\")\n",
    "                if isinstance(val, (list, dict)):\n",
    "                    val = json.dumps(val)\n",
    "                reasoning_parts.append(str(val))\n",
    "\n",
    "        reasoning_text = \" \".join(reasoning_parts).lower()\n",
    "\n",
    "        # Keyword comparison\n",
    "        gt_kw_list = gt_keywords.get(key, [])\n",
    "        matched = [kw for kw in gt_kw_list if kw.lower() in reasoning_text]\n",
    "        unmatched = [kw for kw in gt_kw_list if kw.lower() not in reasoning_text]\n",
    "\n",
    "        report[key] = {\n",
    "            \"gt_keywords\": gt_kw_list,\n",
    "            \"reasoning_text\": reasoning_text,\n",
    "            \"matched\": matched,\n",
    "            \"unmatched\": unmatched,\n",
    "            \"match_count\": len(matched)\n",
    "        }\n",
    "\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5be8ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixtral_reasoning = check_gt_keywords_in_pred_reasoning(gt_keywords, models[\"pixtral\"])\n",
    "mplugowl_reasoning = check_gt_keywords_in_pred_reasoning(gt_keywords, models[\"mplugowl\"])\n",
    "o4_reasoning = check_gt_keywords_in_pred_reasoning(gt_keywords, models[\"o4\"])\n",
    "gemini25_reasoning = check_gt_keywords_in_pred_reasoning(gt_keywords, models[\"gemini25\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "538a448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_reasoning = check_gt_keywords_in_pred_reasoning(gt_keywords, models[\"qwen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3886e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_reasoning = check_gt_keywords_in_pred_reasoning(gt_keywords, models[\"gemini\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "04cab1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_reasoning = check_gt_keywords_in_pred_reasoning(gt_keywords, models[\"gpt4o\"])\n",
    "internv_reasoning = check_gt_keywords_in_pred_reasoning(gt_keywords, models[\"internv\"])\n",
    "videollama_reasoning = check_gt_keywords_in_pred_reasoning(gt_keywords, models[\"videollama\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50b3794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_binary_score(report, model):\n",
    "    count = 0\n",
    "    for k, v in report.items():\n",
    "        if v[\"match_count\"] < 1:\n",
    "            count+=1 \n",
    "    print(\"For model\", model, \"the number of samples that have less than 1 matching keywords with the GT: \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa2d300c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model pixtral the number of samples that have less than 1 matching keywords with the GT:  510\n",
      "For model mplugowl the number of samples that have less than 1 matching keywords with the GT:  100\n",
      "For model o4 the number of samples that have less than 1 matching keywords with the GT:  24\n",
      "For model gemini25 the number of samples that have less than 1 matching keywords with the GT:  54\n"
     ]
    }
   ],
   "source": [
    "compute_binary_score(pixtral_reasoning, 'pixtral')\n",
    "compute_binary_score(mplugowl_reasoning, 'mplugowl')\n",
    "compute_binary_score(o4_reasoning, 'o4')\n",
    "compute_binary_score(gemini25_reasoning, 'gemini25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c525ab16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model qwen the number of samples that have less than 1 matching keywords with the GT:  31\n"
     ]
    }
   ],
   "source": [
    "compute_binary_score(qwen_reasoning, 'qwen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c544f1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model gemini the number of samples that have less than 1 matching keywords with the GT:  8\n"
     ]
    }
   ],
   "source": [
    "compute_binary_score(gemini_reasoning, 'gemini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "e29494c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model gpt the number of samples that have less than 1 matching keywords with the GT:  156\n",
      "For model internv the number of samples that have less than 1 matching keywords with the GT:  181\n",
      "For model videollama the number of samples that have less than 1 matching keywords with the GT:  105\n"
     ]
    }
   ],
   "source": [
    "compute_binary_score(gpt_reasoning, 'gpt')\n",
    "compute_binary_score(internv_reasoning, 'internv')\n",
    "compute_binary_score(videollama_reasoning, 'videollama')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
