# ğŸ§  Agent-X: Generation Pipeline

This directory contains scripts used to generate the **queryâ€“reasoning pairs** that form the basis of the Agent-X benchmark. The pipeline consists of three main stages:

- `video_frames.py` â€” for extracting key frames from videos
- `query_generation.py` â€” for generating realistic, multi-step queries from images
- `reasoning_generation.py` â€” for producing complete step-by-step tool-use reasoning traces in response to the refined queries

---

## ğŸ¬ 0. Video Frame Extraction

**Script:** `video_frames.py`

This utility dynamically extracts frames from video files to use as input for the Agent-X pipeline. Since most vision-language models do not accept raw video input, we sample frames instead.

### ğŸ”¹ What It Does

- Reads all `.mp4`, `.avi`, `.mov`, or `.mkv` files in a given folder
- Dynamically selects `nth` frame based on video length:
  - â‰¤50 frames â†’ every 3rd frame
  - â‰¤200 frames â†’ every 10th frame
  - â‰¤500 frames â†’ every 20th frame
  - â‰¤1000 frames â†’ every 30th frame
  - >1000 frames â†’ every 50th frame
- Saves extracted frames to an output folder as `.jpg`

### ğŸ”¹ Usage

Call the function `extract_every_nth_frame_dynamic(video_folder, output_folder)` in your script or notebook. The output can then be used in `query_generation.py`.

---

## âœ¨ 1. Query Generation

**Script:** `query_generation.py`

This script uses OpenAI's GPT-4o to generate **natural language queries** based on visual inputs. The queries are constrained to be complex, tool-relevant, and human-verifiable, matching Agent-X task requirements.

### ğŸ”¹ Input

- A folder of `.jpg`, `.jpeg`, or `.png` files (configurable via `folder_path`)

### ğŸ”¹ Output

- `Generative_Queries.xlsx`:
  - `File path`
  - `Generated Query`
  - (empty columns for human-refined queries and types)
- `failed_images.txt` â€” list of files that failed to process
- Optional: cleaned file paths in the Excel sheet

### ğŸ“‹ Prompt Constraints

The model is instructed to:

- Require at least **3 reasoning steps**
- Use at least **2 tools** (from a predefined list)
- Not mention tool names directly
- Stay grounded in **realistic**, **time-invariant**, and **evaluable** queries

---

## ğŸ” 2. Reasoning Generation

**Script:** `reasoning_generation.py`

This script takes refined queries and generates detailed **reasoning traces**, including the tools used, their input/output, and justifications for each step.

### ğŸ”¹ Input

- Refined queries from `refined_queries_<batch>.xlsx` (editable by annotators)
- Image(s) or video frame folder corresponding to each query
- Tool metadata from `toolmeta.json`

### ğŸ”¹ Output

- `generated_agent_reasoning_<batch>.xlsx`:
  - `Query`
  - `Reasoning Steps` (tool/task/thought trace)
  - `Final Answer` and its `Justification`
  - `Tools Used` and `Total Steps`

### ğŸ§  What It Does

- Builds a system prompt with all tool descriptions
- Encodes image(s) or video frames to base64
- Feeds the query + image(s) to GPT-4o
- Parses the response into structured JSON and saves the results

---

## ğŸ§ª Notes

- Both scripts require an OpenAI API key in a file named `openai_key.txt`
- The generation pipeline is semi-automated: queries are **machine-generated then human-refined**, and final reasoning is again **machine-generated then validated**
- Output files are in Excel format for easy review

---

## ğŸ”§ Configuration Tips

- Change `folder_path`, `BATCH`, or output filenames at the top of each script
- Ensure `toolmeta.json` is correctly formatted with tool names, inputs, and output descriptions

---

## ğŸ—‚ Example Outputs

### âœ¨ Query Example

| File path              | Generated Query                                    |
|------------------------|----------------------------------------------------|
| reasoning/img1.jpg     | How many children are wearing helmets, and what color are they? |

### ğŸ” Reasoning Trace (Simplified)

| Query | Reasoning Steps | Final Answer | Tools Used |
|-------|------------------|---------------|-------------|
| How many... | Step 1: Detect people â†’ Step 2: Filter children â†’ Step 3: Count helmets | 3 children, red and blue helmets | ObjectDetector, AttributeFilter |
